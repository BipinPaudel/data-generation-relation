output_dir: "results"
seed: 10
task: "SYNTHETIC"
dryrun: False
save_prompts: True
timeout: 0.0
task_config: 
    path: "data/preprocess/"
    outpath: "predicted_llama2_7b.jsonl"
    profile_filter:
      hardness: 1
      certainty: 1
      num_tokens: 3000
    eval: False
gen_model: 
  name: "meta-llama/Meta-Llama-3.1-70B-Instruct"
  provider: "hf"
  model_template: "<|begin_of_text|> You are an expert investigator with years of experience in online profiling and text analysis. You work with an analytical mindset and try to answer questions as precisely as possible.\n\n{prompt}<|eot_id|>"
  dtype: "float16"
  max_workers: 2
  args: {
    max_new_tokens: 500,
    temperature: 0.3
  }