output_dir: "results"
seed: 10
task: "SYNTHETIC"
dryrun: False
save_prompts: True
timeout: 0.0
task_config: 
    path: "data/preprocess/"
    outpath: "predicted_llama2_7b.jsonl"
    profile_filter:
      hardness: 1
      certainty: 1
      num_tokens: 3000
    eval: False
gen_model: 
  name: "Qwen/Qwen2-72B-Instruct"
  provider: "hf"
  model_template: "You are an expert investigator with years of experience in online profiling and text analysis. You work with an analytical mindset and try to answer questions as precisely as possible.\n\n{prompt}"
  dtype: "float16"
  max_workers: 2
  args: {
    max_new_tokens: 500,
    temperature: 0.3
  }